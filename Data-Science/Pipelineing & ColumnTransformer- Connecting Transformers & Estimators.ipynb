{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "* Challenges with current code\n",
    "* Understanding Pipeline\n",
    "* Solving Problems using Pipeline\n",
    "* Challenges with Pipeline\n",
    "* Solving hetrogenous data problem with ColumnTransformer\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges with current code\n",
    "* Dev have to do manually the preprocessing followed by putting the data in the estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_tf = ss.fit_transform(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(trainX_tf, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is incorrect, testX isn't tranformed\n",
    "#rf.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX_tf = ss.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 1, 8, 6, 9, 7, 4, 2, 0, 4, 8, 5, 8, 1, 0, 5, 9, 2, 5,\n",
       "       2, 4, 1, 4, 5, 9, 1, 7, 4, 0, 1, 7, 3, 1, 8, 4, 0, 2, 6, 4, 5, 1,\n",
       "       0, 4, 0, 8, 4, 3, 6, 4, 4, 4, 6, 4, 0, 5, 1, 3, 2, 3, 2, 0, 2, 2,\n",
       "       1, 3, 3, 5, 5, 9, 9, 9, 4, 2, 5, 9, 4, 6, 8, 7, 5, 1, 3, 5, 6, 7,\n",
       "       1, 9, 1, 6, 9, 4, 9, 6, 5, 1, 0, 6, 6, 3, 9, 9, 9, 5, 0, 8, 4, 7,\n",
       "       3, 7, 3, 3, 6, 8, 9, 6, 1, 3, 4, 5, 1, 5, 2, 3, 7, 6, 1, 2, 3, 9,\n",
       "       0, 2, 1, 3, 8, 1, 5, 5, 9, 6, 2, 1, 6, 7, 5, 0, 4, 2, 9, 9, 1, 9,\n",
       "       8, 4, 4, 4, 2, 4, 0, 3, 7, 9, 2, 8, 0, 2, 7, 8, 6, 9, 7, 0, 7, 7,\n",
       "       1, 5, 1, 2, 9, 4, 2, 4, 4, 3, 8, 2, 8, 9, 5, 5, 0, 7, 1, 9, 4, 0,\n",
       "       9, 6, 2, 2, 3, 7, 2, 5, 6, 6, 8, 0, 3, 8, 9, 0, 8, 6, 7, 5, 8, 6,\n",
       "       3, 8, 2, 2, 6, 4, 4, 0, 8, 0, 3, 1, 5, 8, 7, 8, 5, 6, 0, 3, 8, 1,\n",
       "       4, 1, 1, 7, 3, 1, 8, 0, 8, 3, 3, 6, 4, 1, 9, 5, 4, 4, 2, 9, 1, 7,\n",
       "       7, 2, 6, 6, 6, 7, 8, 7, 7, 7, 2, 7, 4, 4, 9, 4, 4, 0, 3, 5, 6, 9,\n",
       "       3, 4, 0, 4, 0, 7, 0, 7, 5, 1, 6, 3, 9, 9, 1, 1, 7, 3, 8, 2, 9, 8,\n",
       "       2, 6, 5, 8, 0, 1, 4, 8, 9, 2, 8, 4, 6, 1, 2, 5, 7, 2, 9, 0, 4, 4,\n",
       "       3, 6, 2, 4, 7, 3, 7, 4, 5, 4, 3, 9, 9, 0, 4, 2, 6, 8, 6, 2, 6, 3,\n",
       "       8, 0, 6, 1, 3, 2, 2, 4, 5, 4, 1, 8, 8, 1, 2, 3, 7, 9, 8, 0, 8, 9,\n",
       "       4, 2, 9, 8, 7, 6, 5, 0, 5, 0, 0, 7, 1, 5, 3, 5, 5, 4, 4, 4, 8, 6,\n",
       "       6, 4, 8, 6, 3, 4, 9, 2, 8, 1, 7, 8, 1, 5, 4, 9, 3, 6, 4, 5, 0, 1,\n",
       "       0, 5, 5, 3, 8, 5, 7, 1, 2, 0, 1, 6, 1, 2, 0, 9, 1, 0, 2, 0, 9, 5,\n",
       "       9, 8, 8, 5, 5, 0, 4, 3, 6, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(testX_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    "* Different features need differnt preprocessing\n",
    "* It's very cumbersome to do things the current way\n",
    "* We have to preserve manually all the preprocessors used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "* It connects preprocessor & estimators & thus removes the need to store them manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_pipeline = make_pipeline(StandardScaler(), RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_pipeline.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 1, 8, 6, 9, 7, 4, 2, 0, 4, 8, 5, 8, 1, 5, 5, 9, 2, 5,\n",
       "       2, 7, 1, 4, 5, 9, 1, 7, 4, 0, 1, 7, 3, 1, 8, 9, 0, 2, 6, 4, 5, 1,\n",
       "       0, 4, 0, 8, 4, 3, 6, 4, 4, 4, 6, 4, 0, 5, 1, 3, 2, 3, 2, 0, 2, 2,\n",
       "       1, 3, 3, 5, 5, 8, 2, 9, 4, 2, 5, 9, 4, 6, 8, 7, 5, 1, 3, 5, 6, 4,\n",
       "       1, 9, 1, 6, 9, 4, 9, 6, 5, 1, 0, 6, 6, 3, 3, 9, 9, 5, 6, 8, 4, 7,\n",
       "       3, 7, 3, 3, 6, 8, 9, 6, 1, 3, 6, 5, 1, 5, 2, 9, 7, 6, 1, 2, 3, 9,\n",
       "       0, 2, 1, 3, 8, 1, 5, 5, 7, 6, 2, 1, 6, 7, 5, 0, 5, 2, 9, 9, 1, 9,\n",
       "       8, 4, 4, 4, 2, 4, 0, 3, 7, 9, 2, 8, 0, 2, 7, 8, 6, 9, 7, 0, 7, 7,\n",
       "       1, 3, 1, 2, 9, 4, 2, 4, 4, 3, 8, 2, 8, 9, 9, 5, 0, 7, 1, 9, 4, 0,\n",
       "       9, 6, 2, 2, 3, 7, 2, 5, 6, 6, 8, 0, 3, 8, 9, 0, 8, 6, 7, 5, 8, 6,\n",
       "       8, 8, 3, 2, 6, 4, 4, 0, 8, 0, 3, 1, 5, 8, 7, 8, 5, 6, 0, 3, 8, 1,\n",
       "       4, 1, 1, 7, 3, 1, 8, 0, 8, 3, 3, 6, 4, 1, 9, 5, 4, 4, 2, 9, 1, 7,\n",
       "       7, 2, 6, 6, 6, 7, 8, 7, 7, 5, 2, 7, 4, 4, 9, 4, 4, 0, 3, 5, 6, 9,\n",
       "       3, 4, 0, 4, 0, 7, 0, 7, 5, 1, 6, 3, 9, 7, 1, 1, 7, 3, 8, 2, 9, 8,\n",
       "       2, 6, 5, 8, 0, 1, 4, 8, 9, 2, 8, 4, 6, 1, 1, 5, 7, 2, 9, 0, 4, 1,\n",
       "       3, 6, 2, 4, 7, 3, 7, 4, 5, 4, 3, 9, 9, 0, 4, 2, 6, 8, 6, 2, 6, 3,\n",
       "       8, 0, 6, 1, 0, 2, 2, 4, 5, 4, 1, 8, 8, 1, 2, 3, 7, 9, 3, 0, 8, 9,\n",
       "       4, 2, 9, 1, 7, 6, 5, 0, 5, 0, 0, 7, 1, 5, 3, 5, 5, 4, 4, 4, 8, 6,\n",
       "       6, 4, 8, 6, 3, 4, 9, 2, 8, 1, 7, 8, 2, 5, 4, 9, 3, 6, 4, 5, 0, 1,\n",
       "       0, 5, 5, 8, 8, 9, 7, 1, 2, 0, 1, 6, 1, 2, 0, 9, 1, 0, 2, 0, 9, 5,\n",
       "       9, 8, 8, 5, 5, 0, 4, 3, 6, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_pipeline.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00122053, 0.01816807, 0.00857868, 0.0081789 ,\n",
       "       0.01796291, 0.00409365, 0.00065628, 0.        , 0.00587447,\n",
       "       0.0282883 , 0.00523326, 0.00950129, 0.03406862, 0.00783087,\n",
       "       0.00072251, 0.        , 0.00481624, 0.01398047, 0.03426814,\n",
       "       0.03692408, 0.04505838, 0.0101396 , 0.        , 0.        ,\n",
       "       0.01494973, 0.04530306, 0.01642391, 0.03816368, 0.0218493 ,\n",
       "       0.055166  , 0.        , 0.        , 0.0389982 , 0.02513865,\n",
       "       0.01982917, 0.0324118 , 0.01760624, 0.01897851, 0.        ,\n",
       "       0.00015879, 0.00665488, 0.0298063 , 0.04416555, 0.02701526,\n",
       "       0.01689037, 0.02807224, 0.        , 0.        , 0.00447629,\n",
       "       0.01159953, 0.02196495, 0.01660934, 0.03576797, 0.01421689,\n",
       "       0.        , 0.        , 0.00487922, 0.01407126, 0.01246016,\n",
       "       0.02156464, 0.02119958, 0.02395519, 0.0040881 ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_pipeline.steps[1][1].feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting Pipeline with Hyper-parameter Tuning\n",
    "* We could determine the best combination of hyper-parameters for preprocessor & estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_pipeline = make_pipeline(StandardScaler(), SelectKBest(k=10, score_func=f_classif), RandomForestClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('selectkbest',\n",
       "                 SelectKBest(k=10,\n",
       "                             score_func=<function f_classif at 0x7efd7e3d3f28>)),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = {'selectkbest__k':[20,30,40], 'randomforestclassifier__n_estimators':[100,200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'selectkbest__k':[50,55,60], 'randomforestclassifier__n_estimators':[200,250]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(digit_pipeline, param_grid=params, cv=5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awantik/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [ 0 32 39] are constant.\n",
      "  UserWarning)\n",
      "/home/awantik/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('standardscaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('selectkbest',\n",
       "                                        SelectKBest(k=10,\n",
       "                                                    score_func=<function f_classif at 0x7efd7e3d3f28>)),\n",
       "                                       ('randomforestclassifier',\n",
       "                                        RandomForestClassifier(bootstrap=True,\n",
       "                                                               class_weight=None,\n",
       "                                                               criterion='gini',\n",
       "                                                               max_dept...\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=4,\n",
       "             param_grid={'randomforestclassifier__n_estimators': [200, 250],\n",
       "                         'selectkbest__k': [50, 55, 60]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforestclassifier__n_estimators': 200, 'selectkbest__k': 55}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9732739420935412"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.predict(testX[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('selectkbest',\n",
       "                 SelectKBest(k=55,\n",
       "                             score_func=<function f_classif at 0x7efd7e3d3f28>)),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=200, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Transformer for dealing with hetrogenous data\n",
    "* Regular Pipeline intends to do same processing for all the columns\n",
    "* This doesn't work for hetrogenous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/edyoda/Data-Scientist-program/blob/master/Assignment/images/ColumnTranformer.png?raw=true\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_data = pd.read_csv('https://raw.githubusercontent.com/edyoda/data-science-complete-tutorial/master/Data/HR_comma_sep.csv.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_data.rename(columns={'sales':'dept'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>dept</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.94</td>\n",
       "      <td>6</td>\n",
       "      <td>285</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12579</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8683</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4</td>\n",
       "      <td>213</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4</td>\n",
       "      <td>263</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4451</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.68</td>\n",
       "      <td>5</td>\n",
       "      <td>187</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "309                  0.10             0.94               6   \n",
       "12579                0.39             0.55               2   \n",
       "8683                 0.23             0.96               4   \n",
       "12495                0.82             0.99               4   \n",
       "4451                 0.87             0.68               5   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident  left  \\\n",
       "309                     285                   4              0     1   \n",
       "12579                   159                   3              0     1   \n",
       "8683                    213                   4              0     0   \n",
       "12495                   263                   6              0     1   \n",
       "4451                    187                   3              0     0   \n",
       "\n",
       "       promotion_last_5years       dept  salary  \n",
       "309                        0    support  medium  \n",
       "12579                      0  technical    high  \n",
       "8683                       0  technical  medium  \n",
       "12495                      0  technical  medium  \n",
       "4451                       0      sales     low  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = hr_data.drop(columns=['left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = hr_data.left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Differnt columns needs differnt preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data = feature_data.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "satisfaction_level       float64\n",
       "last_evaluation          float64\n",
       "number_project             int64\n",
       "average_montly_hours       int64\n",
       "time_spend_company         int64\n",
       "Work_accident              int64\n",
       "promotion_last_5years      int64\n",
       "dept                      object\n",
       "salary                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#satisfaction_level & last_evaluation don't need preprocessing\n",
    "#number_project,average_montly_hours,time_spend_company,Work_accident,promotion_last_5years need MinMaxScaler\n",
    "#dept & Salary need OrdinalEncoder\n",
    "feature_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_data = feature_data.select_dtypes(include=['float'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation\n",
       "0                0.38             0.53\n",
       "1                0.80             0.86\n",
       "2                0.11             0.88\n",
       "3                0.72             0.87"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_data = feature_data.select_dtypes(include=['int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_pipeline = make_pipeline(SimpleImputer(),OrdinalEncoder())\n",
    "#SimpleImpter is for handling missing data in pipeline\n",
    "\n",
    "cat_pipeline = make_pipeline(OrdinalEncoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_pipeline = make_pipeline(MinMaxScaler(), SelectKBest(k=3,score_func=f_classif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "              (cat_pipeline,cat_data.columns),\n",
    "              (int_pipeline,int_data.columns),\n",
    "              remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(preprocessor, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,testX, trainY, testY = train_test_split(feature_data, target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>dept</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14443</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.83</td>\n",
       "      <td>6</td>\n",
       "      <td>244</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>accounting</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12791</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.49</td>\n",
       "      <td>4</td>\n",
       "      <td>276</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "14443                0.11             0.83               6   \n",
       "12791                0.82             0.49               4   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident  \\\n",
       "14443                   244                   4              0   \n",
       "12791                   276                   4              0   \n",
       "\n",
       "       promotion_last_5years        dept salary  \n",
       "14443                      0  accounting    low  \n",
       "12791                      0     support    low  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awantik/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('pipeline-1',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('ordinalencoder',\n",
       "                                                                   OrdinalEncoder(categories='auto',\n",
       "                                                                                  dtype=<class 'numpy.float64'>))],\n",
       "                                                           verbose=False),\n",
       "                                                  Index(['dept', 'salary'], dtype='object')),\n",
       "                                                 ('pipe...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(testX[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866666666666667"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pipeline-1', Pipeline(memory=None,\n",
       "           steps=[('ordinalencoder',\n",
       "                   OrdinalEncoder(categories='auto',\n",
       "                                  dtype=<class 'numpy.float64'>))],\n",
       "           verbose=False), Index(['dept', 'salary'], dtype='object')),\n",
       " ('pipeline-2', Pipeline(memory=None,\n",
       "           steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                  ('selectkbest',\n",
       "                   SelectKBest(k=3,\n",
       "                               score_func=<function f_classif at 0x7efd7e3d3f28>))],\n",
       "           verbose=False), Index(['number_project', 'average_montly_hours', 'time_spend_company',\n",
       "         'Work_accident', 'promotion_last_5years'],\n",
       "        dtype='object'))]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.steps[0][1].transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'columntransformer__pipeline-2__selectkbest__k':[2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipeline, param_grid=params, n_jobs=4, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('columntransformer',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='passthrough',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('pipeline-1',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('ordinalencoder',\n",
       "                                                                                          OrdinalEncoder(categories='auto',\n",
       "                                                                                                         dtype=<class 'numpy.float64'>))],\n",
       "                                                                                  ve...\n",
       "                                                               min_impurity_split=None,\n",
       "                                                               min_samples_leaf=1,\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=10,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=4,\n",
       "             param_grid={'columntransformer__pipeline-2__selectkbest__k': [2,\n",
       "                                                                           3]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columntransformer__pipeline-2__selectkbest__k': 3}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9847986487687794"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disadvantages of Pipeline\n",
    "* Doesn't support Online Learning\n",
    "* Online Learning will be discussed later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with imbalanced data in pipeline\n",
    "* Use imblearn make_pipeline rather than scikit make_pipeline as RandomOverSampler is not supported in scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11428\n",
       "1     3571\n",
       "Name: left, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This make_pipeline is not scikit pipeline but imblearn pipeline which support Oversampler as part of pipeline\n",
    "pipeline = make_pipeline(preprocessor, RandomOverSampler(), RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awantik/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('pipeline-1',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('ordinalencoder',\n",
       "                                                                   OrdinalEncoder(categories='auto',\n",
       "                                                                                  dtype=<class 'numpy.float64'>))],\n",
       "                                                           verbose=False),\n",
       "                                                  Index(['dept', 'salary'], dtype='object')),\n",
       "                                                 ('pipe...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9864"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
