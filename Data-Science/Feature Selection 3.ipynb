{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "* Introduction to Embedded Methods\n",
    "* Advantages\n",
    "* Process\n",
    "* Introduction to Hybrid Methods\n",
    "* Advantages\n",
    "* Process\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to Embedded Methods\n",
    "* Feature selection happens during model training that's why called embedded methods\n",
    "\n",
    "#### Advantages\n",
    "* Feature interaction with target is considered. ( advantage of wrapper based methods )\n",
    "* Fast like filter based methods.\n",
    "* More accurate than filter based methods.\n",
    "* Less prone to overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process of applying Embedded Methods\n",
    "* First these methods train machine learning models\n",
    "* They then derive feature importances from the trained model.\n",
    "* And, finally removing non-important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods\n",
    "* Regularization Based\n",
    "* Tree Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization based\n",
    "* Using regularization technique, the learned weights (w0, w1, ...) are threasholded so that their individual impact on the prediction is reduced.\n",
    "* By tapping down feature, it makes sure that some specific features don't become over important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularization in Linear Regression Models\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame([[0,0,0],[0,0,.1],[1,1,1]], columns=['A','B','Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B    Y\n",
       "0  0  0  0.0\n",
       "1  0  0  0.1\n",
       "2  1  1  1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso(alpha=.1)\n",
    "\n",
    "lasso.fit(data[['A','B']], data.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0. ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(data[['A','B']], data.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.475, 0.475])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PS : Feature Selection is happening as a part of model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Panelty calculation needs to be understood\n",
    "* L1 regularization  - shrinks come of the coefs to zero thus suited for feature selection - Lasso\n",
    "* L2 regularization  - it does't set weights to be zero - Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PS : This is how you achieve feature selection in embedding method for LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree Based feature importances\n",
    "* Tree based models like randomforest\n",
    "* Let's understand RandomForest for a while"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest\n",
    "* Base understanding, train empty trees with different subset of data. And, it will generate different trees.\n",
    "* For doing the prediction (classification), all the participating trees predict. And, majority decides the prediction.\n",
    "* These composition of trees is known as RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7feb498ea048>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[110], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., 10., 15.,  0.,  0.,  0.,  0.,  0., 11., 15.,  3.,\n",
       "        0.,  0.,  0.,  0.,  7., 15.,  4.,  0.,  0.,  0.,  0.,  0., 12.,\n",
       "       11.,  1.,  3.,  8.,  2.,  0.,  0.,  4., 12., 15., 15., 16.,  9.,\n",
       "        0.,  0.,  0.,  0.,  8., 16.,  8.,  2.,  0.,  0.,  0.,  0., 10.,\n",
       "       12.,  0.,  0.,  0.,  0.,  0.,  0., 12.,  9.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data[110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target[110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8622222222222222"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.02, 0.01, 0.01, 0.02, 0.01, 0.  , 0.  , 0.01, 0.03,\n",
       "       0.01, 0.02, 0.03, 0.01, 0.  , 0.  , 0.01, 0.02, 0.03, 0.03, 0.05,\n",
       "       0.01, 0.  , 0.  , 0.01, 0.04, 0.02, 0.03, 0.02, 0.03, 0.  , 0.  ,\n",
       "       0.03, 0.03, 0.02, 0.04, 0.02, 0.03, 0.  , 0.  , 0.01, 0.04, 0.04,\n",
       "       0.02, 0.02, 0.02, 0.  , 0.  , 0.  , 0.02, 0.02, 0.01, 0.02, 0.02,\n",
       "       0.  , 0.  , 0.  , 0.02, 0.01, 0.02, 0.03, 0.02, 0.  ])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.round(rf.feature_importances_,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Hybrid Methods\n",
    "* Rather than using a single approch to do feature subset select, hybrid methods as the names combine different approaches to get best possible feature subset.\n",
    "* It's like starting with filter based methods to remove contant of similar data.\n",
    "* Followed by using wrapper based methods\n",
    "\n",
    "#### Advantages\n",
    "* High accuracy models\n",
    "* Robust models\n",
    "\n",
    "#### Process\n",
    "* Using Filter & Wrapper methods\n",
    "  - using f_classif choose some important features. (reduces the feature space) 100 - 75\n",
    "  - using SequentialFeatureSelector get top features from the selected ones 75-25\n",
    "  \n",
    "* Using Embedded & Wrapper methods\n",
    "  - Lasso for identifying importnat features or decision tree.\n",
    "  - Choosing top 50% features & applying wrapper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A fancy way of naming the above things\n",
    "* reducing the feature dimension using incremental techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/edyoda/data-science-complete-tutorial/master/Data/winequality-white.csv', sep=';')\n",
    "def f(r):\n",
    "    if r <= 3:\n",
    "        return 1\n",
    "    elif r<= 6:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "df.quality = df.quality.map(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.remove('quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(df[features], df.quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.Series(dt.feature_importances_, index=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5 = list(fi.sort_values(ascending=False)[:5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = df[top5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(feature_data, df.quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.856326530612245"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some reading assignments\n",
    "* Probability Basics & Conditional Probability\n",
    "* https://developers.google.com/machine-learning/guides/good-data-analysis\n",
    "* https://developers.google.com/machine-learning/guides/rules-of-ml\n",
    "\n",
    "### Next topic\n",
    "* Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
